{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural bioinformatic analysis of LiP-MS data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides examples for how to map peptides generated in the LiP-MS workflow to protein structures, and to compute/match different structural descriptors to the identified peptides. A prerequisite for performing the structural analysis is that you have computed a list of peptides and corresponding UniProt IDs. \n",
    "\n",
    "The code is written in Python (v3.7), and is dependent on the following libraries (versions used are in brackets): \n",
    "\n",
    "- pandas (v1.1.5)\n",
    "- numpy (v1.19.4)\n",
    "- Biopython (v1.78)\n",
    "- seaborn (v0.11)\n",
    "- matplotlib (v3.3.3)\n",
    "\n",
    "\n",
    "The script provided should be considered a starting point for your own analysis and may need adaptation dependent on the questions you want to address.\n",
    "\n",
    "#### Codeauthor: \n",
    "Fabian Sesterhenn, PhD <br/>\n",
    "\n",
    "fabian.sesterhenn@gmail.com \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load dependencies and dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b09e23530d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mBio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import Bio.PDB\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import gzip\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio import pairwise2\n",
    "\n",
    "from IPython.display import Javascript, display\n",
    "import ipywidgets as widgets\n",
    "pd.set_option(\"display.max_columns\",100)\n",
    "\n",
    "# Hide warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a21d58c5457b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load example dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/LiP_corrected_short.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load example dataset \n",
    "data = pd.read_csv(\"./data/LiP_corrected_short.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce example dataset \n",
    "#data = data[data[\"Label\"]==\"IPTG_1_ vs IPTG_2_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column containing UniProtID only \n",
    "data[\"UPID\"] = data[\"ProteinName\"].apply(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicate column names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0168357dc388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Filter dataframe to selected columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUPID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msignificance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# indicate column names of peptide, UniProtID, and the column containing a pvalue/adjusted pvalue. Make sure you only have proteotypic peptides. \n",
    "pep = \"PeptideSequence\"\n",
    "UPID = \"UPID\"\n",
    "significance = \"adj.pvalue\"\n",
    "pvalue_cutoff = 0.05\n",
    "\n",
    "# Filter dataframe to selected columns\n",
    "df = data[[UPID,pep,significance]]\n",
    "\n",
    "\n",
    "# Choose significance threshold for plotting \n",
    "\n",
    "df[\"significant\"] = df[significance].apply(lambda x: True if x<pvalue_cutoff else False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load structural descriptors and match them to the peptides of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structural descriptors used here have been computed and published by [Zhao et al., 2021](https://doi.org/10.1093/nar/gkaa931). Structural descriptors for 83 proteomes can be accessed [here](http://biomine.cs.vcu.edu/servers/DESCRIBEPROT/) and are available for download. Here, we provide pre-processed files containing secondary structure predictions (PSIPRED) and disorder predictions (VSL2B) based on the data deposited in DESCRIBEPROT. The provided files are in json format and contain python dictionaries, with keys being UniProt IDs and the values being either sequence, secondary structure prediction or disorder propensity.  \n",
    "\n",
    "Files are provided for four organisms: \n",
    "- human\n",
    "- mouse\n",
    "- yeast (S. cerevisiae)\n",
    "- E.coli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are working with an E.coli dataset - so load the descriptors for E.coli: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = widgets.Dropdown(\n",
    "    options=['human', 'Scerevisiae', 'Ecoli',\"mouse\"],\n",
    "    disabled=False)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.execute_cell_range(IPython.notebook.get_selected_index()+1, IPython.notebook.ncells())"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678f83720a774693adc4dc90bb162dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run script', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_all(ev):\n",
    "    display(Javascript('IPython.notebook.execute_cell_range(IPython.notebook.get_selected_index()+1, IPython.notebook.ncells())'))\n",
    "\n",
    "button = widgets.Button(description=\"Run script\")\n",
    "button.on_click(run_all)\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/\"+w.value+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence\n",
    "with open(path+\"UPseq_\"+w.value+\".json\") as fi: \n",
    "    seq = json.load(fi)\n",
    "\n",
    "# Secondary structure prediction\n",
    "with open(path+\"UPPSI_\"+w.value+\".json\") as fi: \n",
    "    psi = json.load(fi)\n",
    "\n",
    "# Disorder prediction\n",
    "with open(path+\"UPID_VSL2B_\"+w.value+\".json\") as fi: \n",
    "    diso = json.load(fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Add new columns to dataframe containing predicted secondary structure content and disorder for each peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SEQ\"] = df[UPID].map(seq)\n",
    "df[\"PSIPRED\"] = df[UPID].map(psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idlist = df[UPID].to_list()\n",
    "peplist = df[pep].to_list()\n",
    "seqlist = df[\"SEQ\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ss_peptide(df,colname_ids = UPID,colname_pepseq=pep,colname_seq = \"SEQ\",colname_psipred = \"PSIPRED\"):\n",
    "\n",
    "    pep_psi = []\n",
    "    seqs = df[colname_seq].to_list()\n",
    "    psi = df[colname_psipred].to_list()\n",
    "    for i,x in enumerate(peplist):\n",
    "        \n",
    "        m = re.search(str(x),str(seqs[i]))\n",
    "        if m:\n",
    "            if (str(psi[i]) !=\"NaN\" and str(psi[i]) !=\"nan\"):\n",
    "                ppsi = str(psi[i][m.start():m.end()])\n",
    "                pep_psi.append(ppsi)\n",
    "            else:\n",
    "                pep_psi.append(\"X\")\n",
    "        else:\n",
    "            pep_psi.append(\"X\")\n",
    "    df[\"peptide_psipred\"] = pep_psi\n",
    "    df[\"%loop_pep\"] = df[\"peptide_psipred\"].apply(lambda x: x.count(\"C\")/len(x))\n",
    "    df[\"%helix_pep\"] = df[\"peptide_psipred\"].apply(lambda x: x.count(\"H\")/len(x))\n",
    "    df[\"%beta_pep\"] =df[\"peptide_psipred\"].apply(lambda x: x.count(\"E\")/len(x))\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = compute_ss_peptide(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_diso = {}\n",
    "for i,x in enumerate(peplist):\n",
    "    m = re.search(str(x),str(seqlist[i]))\n",
    "    if m: \n",
    "        try:\n",
    "            temp = diso[idlist[i]]\n",
    "            ppsi = np.mean(temp[m.start():m.end()])\n",
    "    \n",
    "        except:\n",
    "            ppsi = np.nan\n",
    "    else:\n",
    "        ppsi = np.nan\n",
    "    pep_diso.update({peplist[i]:ppsi})\n",
    "\n",
    "df2[\"Disorder\"] = df2[pep].map(pep_diso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output: Dataframe with secondary structure and disorder content for each peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Add a PDB structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_dict(df, key, value):\n",
    "    '''''\n",
    "    This function takes as input a dataframe and returns a dictionary of two selected columns. The values are organized as a list.\n",
    "    '''''\n",
    "    dic = {k: list(set(g[value].tolist())) for k,g in df.groupby(key)}\n",
    "    return dic\n",
    "\n",
    "def retrieve_pdb2(name):\n",
    "    url = \"https://files.rcsb.org/download/\"\n",
    "\n",
    "    cmd = \"wget \"+url+name\n",
    "\n",
    "    if not os.path.isfile(name):\n",
    "        print(cmd)\n",
    "        os.system(cmd)\n",
    "\n",
    "def extract_sequence_from_pdb(infile, chain):\n",
    "    threetoone = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N',\n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W',\n",
    "     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
    "    pdb = open(infile,\"r\")\n",
    "    pdb = pdb.readlines()\n",
    "    sequence = []\n",
    "    for line in pdb:\n",
    "        if line.startswith(\"ATOM\"):\n",
    "            if line[21:22].strip() == chain:\n",
    "                if line[13:16].strip() == \"CA\":\n",
    "                    sequence.append((threetoone[line[17:20]]))\n",
    "\n",
    "    return(\"\".join(sequence))\n",
    "\n",
    "def find_representative_pdb(pep_dict):\n",
    "    '''''\n",
    "    identifies a representative pdb structure (one, not several). Needs UPPDB dictionary preloaded. Extracts sequences on-the-fly.\n",
    "    Input is a pep_dict, generated by: 'pep_dict = convert_df_to_dict(df,\"Prot\",\"Pep\")'\n",
    "\n",
    "    returns pep_pdb dictionary that has the peptide and a representative pdb structure that contains this peptide sequence. can be added to original dataframe\n",
    "    by df[\"representative_PDB\"] = df[\"Pep\"].map(find_representative_pdb(pep_dict))\n",
    "    '''''\n",
    "\n",
    "    with open('./data/general/UPID_PDB_CHAIN.json', 'r') as fp:\n",
    "        UPPDB = json.load(fp)\n",
    "    pep_pdb_only = {}\n",
    "    for upid,pep in pep_dict.items():\n",
    "        count = 0\n",
    "        try:\n",
    "            pdb = UPPDB[upid]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        for p in pdb:\n",
    "            if count < 1:\n",
    "                p=str(p)\n",
    "                name = p.split(\"_\")[0]+\".pdb\"\n",
    "                chain = p.split(\"_\")[1]\n",
    "                if not os.path.isfile(name):\n",
    "                    retrieve_pdb2(name)\n",
    "                try:\n",
    "                    ss = extract_sequence_from_pdb(name,chain)\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "                if ss:\n",
    "                    for pe in pep:\n",
    "                        if pe in ss:\n",
    "                            count = 1\n",
    "                            pep_pdb_only.update({pe:p})\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "    return pep_pdb_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A new dataframe is created here with only 300 entries, to reduce runtime in this example. Needs to be adjusted if you want to run it for your entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing this can take a while depending on the size of the dataframe and the number of PDB structures, as PDB structures are downloaded and then a new column is added to the dataframe with a representative PDB structure.\n",
    "# Consider to reduce the size of your dataframe to only the necessary entries before starting to download. \n",
    "df3 = df2.head(300)\n",
    "pep_dict = convert_df_to_dict(df3,UPID,pep)\n",
    "df3[\"representative_PDB\"] = df[pep].map(find_representative_pdb(pep_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df3[UPID].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Create a list of commands to load in PyMol and visualize the identified peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/general/UPID_PDB_CHAIN.json\") as fi: \n",
    "    UPPDB = json.load(fi)\n",
    "with gzip.open(\"./data/general/PDB_CHAIN_SEQ.json.gz\") as fi: \n",
    "    PDBseqs = json.load(fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate function to retrieve PDB files in pymol and color peptides according to significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PDBs_highlight_peptides(df=df,colname_ids = UPID,colname_pepseq=pep,colname_pvalue = significance,fetchall=False,maxlim=5,significance_cutoff=0.05):\n",
    "\n",
    "    '''''\n",
    "    input is a dataframe, the name of the column with the UniProtIDs, the peptide sequence and a column containing pvalues. Significance cutoff is 0.05 by default, and peptides with a smaller pval are colored red, all others black. \n",
    "    The fetchall option allows to retrieve all PDBs, even if the peptide of interest is not contained in the PDB structure (default=False)\n",
    "    Maxlim is set to 5 by default, so that a maximum of 5 PDB structures are retrieved for each uniprot entry. \n",
    "    \n",
    "    The dataframe will initially be sorted in descending order according to the significance peptide column. \n",
    "    This ensures that peptides that are significant will be colored last, and thus will not be overwritten by the color of an overlapping non-significant peptide. \n",
    "    \n",
    "    The output is a file to copy/paste in pymol, containing the commands to retrieve pdb files,\n",
    "    group them and highlight the peptides by color.\n",
    "    This function relies on  the find_seq.py script for finding and highlighting the peptide sequence.\n",
    "\n",
    "    '''''\n",
    "    \n",
    "    df = df.sort_values(by=colname_pvalue,ascending=False)\n",
    "    \n",
    "    query = convert_df_to_dict(df,colname_ids,colname_pepseq)\n",
    "\n",
    "    pep_pval = convert_df_to_dict(df,colname_pepseq,colname_pvalue)\n",
    "    \n",
    "    log = open(\"error.log\",\"w\")\n",
    "    output = open(\"pymol_commands.txt\",\"w\")\n",
    "    output.write(\"run findseq.py\"+\"\\n\")\n",
    "    output.write(\"bg_color white\" +\"\\n\")\n",
    "    for s in query.keys():\n",
    "        pdb = []\n",
    "        pdb3 = []\n",
    "        try:\n",
    "            pdb.append(UPPDB[s])\n",
    "        except KeyError:\n",
    "            e1 = \"no corresponding PDB for \"+s\n",
    "            log.write(e1+\"\\n\")\n",
    "            continue\n",
    "        pdb2 = [val for sublist in pdb for val in sublist]\n",
    "        if len(pdb2) == 0:\n",
    "                print(\"length 0\")\n",
    "                continue\n",
    "        else:\n",
    "            for i,p in enumerate(pdb2[:maxlim]):\n",
    "                try:\n",
    "                    p = p.strip()\n",
    "                    seq = PDBseqs[str(p)]\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        pdbid = pdb2[i].split(\"_\")[0]\n",
    "                        pdbchain = pdb2[i].split(\"_\")[1]\n",
    "                        seq = extract_sequence_from_pdb(pdbid,pdbchain)\n",
    "                    except:\n",
    "                        continue\n",
    "                command1 = \"fetch \" + p\n",
    "                command2 = \"color lightblue, \" +p\n",
    "\n",
    "                for x in query[s]:\n",
    "                    pdbid = pdb2[i].split(\"_\")[0]\n",
    "                    pdbchain = pdb2[i].split(\"_\")[1]\n",
    "                    if str(x) in str(seq):\n",
    "                            start = str(seq).index(x)-1\n",
    "                            length = len(x)\n",
    "                            end = start + length\n",
    "                            \n",
    "\n",
    "                            if pep_pval[x][0] < significance_cutoff:\n",
    "                                color = \"red\"\n",
    "                            else: \n",
    "                                color = \"black\"\n",
    "\n",
    "                            find = \"findseq \"+x+\", \"+p+\", \"+p+\"_\"+x\n",
    "                            coloring  = \"color \" +color+\", \"+p+\"_\"+x\n",
    "                            pdb3.append(p)\n",
    "                            print(command1+\"\\n\")\n",
    "                            print(find)\n",
    "                            print(coloring+\"\\n\")\n",
    "                            print(\"delete \"+p+\"_\"+x+\"\\n\")\n",
    "                            output.write(command1+\"\\n\")\n",
    "                            output.write(find+\"\\n\"+coloring+\"\\n\")\n",
    "                            output.write(\"delete \"+p+\"_\"+x+\"\\n\")\n",
    "                    else:\n",
    "                            e2 = x+ \" could not be found in \"+pdbid\n",
    "                            log.write(e2+\"\\n\")\n",
    "                            if fetchall:\n",
    "                                output.write(command1+\"\\n\")\n",
    "        if fetchall:\n",
    "            output.write(\"group \"+ s+\",\"+(\" \".join(x for x in pdb2))+\"\\n\")\n",
    "            print(\"group \"+ s+\",\"+(\" \".join(x for x in pdb2)))\n",
    "        else:\n",
    "            if len(pdb3)==0:\n",
    "                continue\n",
    "            else:\n",
    "                output.write(\"group \"+ s+\",\"+(\" \".join(x for x in pdb3))+\"\\n\")\n",
    "                print(\"group \"+ s+\",\"+(\" \".join(x for x in pdb3)))\n",
    "    log.close()\n",
    "    output.close()\n",
    "    return log, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call function and copy output in PyMol. Instead of copying, you can also use \"run pymol_scripts/execute_commands.py\". This script will execute the commands written in the file \"pymol_commands.txt\" line by line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_PDBs_highlight_peptides(df3,UPID,pep,significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Color peptides according to significance in a selected pair of UniProtID and PDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_peptides_in_selected_PDB(df,UPID,PDB,colname_ids, colname_pepseq, colname_pvalue =\"significance\", significance_cutoff=0.05):\n",
    "    \n",
    "    '''''\n",
    "    Function to color peptides in a selected pair of UniProtID and PDB structure. Input is your dataframe that will be filtered according to the UniProt entry, \n",
    "    and sorted by the column indicating significance. \n",
    "    All peptides for this uniprot ID will be searched in the PDB you indicate (format: PDBCODE_CHAIN).\n",
    "    The PDB will be loaded into pymol, colored in lightblue by default, and then peptides below the significance cutoff (to be specified, default 0.05) will be colored red, all other detected peptides are black. \n",
    "    Output is a file called \"pymol_commands.txt\" in the same working directory, that can be copied to pymol. Requires the findseq.py script. \n",
    "        \n",
    "    '''''\n",
    "    \n",
    "    df2 = df[df[colname_ids]==UPID].sort_values(by=colname_pvalue,ascending=False)\n",
    "    \n",
    "    peps = df2[colname_pepseq].to_list()\n",
    "    \n",
    "    pep_pval = convert_df_to_dict(df2,colname_pepseq,colname_pvalue)\n",
    "    \n",
    "    pdb_name = PDB.split(\"_\")[0]\n",
    "    pdb_name2 = PDB.split(\"_\")[0]+\".pdb\"\n",
    "    pdb_chain = PDB.split(\"_\")[1]\n",
    "\n",
    "    output = open(\"pymol_commands.txt\",\"w\")\n",
    "    output.write(\"run findseq.py\"+\"\\n\")\n",
    "    output.write(\"bg_color white\" +\"\\n\")\n",
    "    output.write(\"fetch \" + pdb_name +\"\\n\")\n",
    "    output.write(\"color lightblue, \"+pdb_name+\"\\n\")\n",
    "    \n",
    "    \n",
    "    for ind,p in enumerate(peps): \n",
    "        if pep_pval[p][0] < significance_cutoff:\n",
    "\n",
    "            output.write(\"findseq \"+p+\", \"+pdb_name+\", seq_\"+p+\"\\n\")\n",
    "            output.write(\"color red, \"+\"seq_\"+p+\"\\n\")\n",
    "            output.write(\"delete \"+\"seq_\"+p+\"\\n\")\n",
    "        else:\n",
    "            output.write(\"findseq \"+p+\", \"+pdb_name+\", seq_\"+p+\"\\n\")\n",
    "            output.write(\"color black, \"+\"seq_\"+p+\"\\n\")\n",
    "            output.write(\"delete \"+\"seq_\"+p+\"\\n\")\n",
    "            \n",
    "    output.close()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call function. Output file will be written to your working directory and can be copied into PyMol to load the PDB and highlight all peptides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_peptides_in_selected_PDB(df3,\"P00350\",\"2ZYA_B\",UPID,pep,significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Measure distances to known functional sites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load dependencies - functional site annotations from UniProt (December 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+w.value+'_bind_sites.json', 'r') as fp:\n",
    "    bindingsites = json.load(fp)\n",
    "with open(path+w.value+'_active_sites.json', 'r') as fp:\n",
    "    activesites = json.load(fp)\n",
    "with open(path+w.value+'_nucleotide_binding.json', 'r') as fp:\n",
    "    nucleotidebinding = json.load(fp)\n",
    "with open(path+w.value+'_metal_binding.json', 'r') as fp:\n",
    "    metalbinding = json.load(fp)\n",
    "with open(path+w.value+'_calcium_binding.json', 'r') as fp:\n",
    "    calciumbinding = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_dict = convert_df_to_dict(df3,UPID,pep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_representative_pdb = find_representative_pdb(pep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_value(dict_obj, key, value):\n",
    "    '''''\n",
    "    This function is useful for creating a dictionary where new values can be added and do not replace the value if the key was already in the dict.\n",
    "    Use instead of dict.update()\n",
    "    USAGE: append_value(dict,key,value). Can also be as dict inside a dict: append_value(pep_coord,k,{x:pep_coordinates})\n",
    "\n",
    "    '''''\n",
    "    # Check if key exist in dict or not\n",
    "    if key in dict_obj:\n",
    "        # Key exist in dict.\n",
    "        # Check if type of value of key is list or not\n",
    "        if not isinstance(dict_obj[key], list):\n",
    "            # If type is not list then make it list\n",
    "            dict_obj[key] = [dict_obj[key]]\n",
    "        # Append the value in list\n",
    "        dict_obj[key].append(value)\n",
    "    else:\n",
    "        # As key is not in dict,\n",
    "        # so, add key-value pair\n",
    "        dict_obj[key] = value\n",
    "    return\n",
    "        \n",
    "        \n",
    "def extract_coords(infile, chain):\n",
    "    '''''\n",
    "    Extracts Calpha coordinates from a PDB file. \n",
    "    Input: PDB and chain identifier. \n",
    "    \n",
    "    '''''\n",
    "    \n",
    "    \n",
    "    threetoone = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "     'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N',\n",
    "     'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W',\n",
    "     'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
    "\n",
    "    pdb = open(infile,\"r\")\n",
    "    chain = chain\n",
    "    pdb = pdb.readlines()\n",
    "    sequence = []\n",
    "    coords = []\n",
    "\n",
    "    output = {}\n",
    "    for line in pdb:\n",
    "        if line.startswith(\"ATOM\"):\n",
    "            if line[21:22].strip() == chain:\n",
    "                if line[13:16].strip() == \"CA\":\n",
    "                    sequence.append((threetoone[line[17:20]]))\n",
    "                    xcoords=float(line[30:38].strip())\n",
    "                    ycoords=float(line[39:46].strip())\n",
    "                    zcoords=float(line[47:54].strip())\n",
    "                    ar = np.array([xcoords,ycoords,zcoords])\n",
    "                    coords.append(ar)\n",
    "    seq = \"\".join(sequence)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates_peptides(pep_dict,seq=seq,data_representative_pdb=data_representative_pdb):\n",
    "    '''''\n",
    "    Input: dictionary with the UniProtID:[peptides]. \n",
    "    Requirements: \n",
    "    1) load UniProtID:sequence dictionary (\"seq\"). \n",
    "    2) Create dictionary with peptide:PDB from your dataframe (\"data_representative_pdb\")\n",
    "    Output: dictionary containing the peptides with their coordinates as np.array (pep_coord)\n",
    "    \n",
    "    '''''\n",
    "    pep_coord = {}\n",
    "    for k, v in pep_dict.items():\n",
    "        \n",
    "        temp_dict = {}\n",
    "        \n",
    "        for x in v: \n",
    "            try:\n",
    "                m = re.search(x,seq[k])\n",
    "                pdb = data_representative_pdb[x]\n",
    "    \n",
    "                name = pdb.split(\"_\")[0]+\".pdb\"\n",
    "                chain = pdb.split(\"_\")[1]\n",
    "\n",
    "                if not os.path.isfile(name):\n",
    "                    retrieve_pdb2(name)\n",
    "\n",
    "                s  = extract_sequence_from_pdb(name,chain)\n",
    "\n",
    "\n",
    "                o = re.search(x,s)\n",
    "                xx = extract_coords(name,chain)\n",
    "                pep_coordinates = xx[o.start():o.end()]\n",
    "                temp_dict.update({x:pep_coordinates})\n",
    "                pep_coord.update({k:temp_dict})\n",
    "                #append_value(pep_coord,k,{x:pep_coordinates})\n",
    "\n",
    "            except KeyError:\n",
    "                continue\n",
    "    return pep_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = extract_coordinates_peptides(pep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a80ffa0c0e84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_distance_to_func_site\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctionalsites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpep_coord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolname_pep\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     '''''\n\u001b[1;32m      4\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfunctionalsites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0muniprot\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresidues\u001b[0m \u001b[0mannotated\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0msite\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mbinding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pep' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_distance_to_func_site(functionalsites,df,pep_coord,colname_pep =pep):\n",
    "    \n",
    "    '''''\n",
    "    input: \n",
    "    functionalsites = dictionary with uniprot ids and a list of residues annotated as functional site (e.g. binding, active site)\n",
    "    df = your dataframe  \n",
    "    pep_coord = output from extract_coordinates_peptides() function\n",
    "    colname_pep = name of the column that contains the peptide sequence\n",
    "    \n",
    "    output: \n",
    "    dictionary with peptide:minimal Calpha distance to a functionalsite (minimal distance to the closest functional site only!)\n",
    "    \n",
    "    '''''\n",
    "       \n",
    "    # 1) Create artificial peptides around the functional site (+/-3 residues) \n",
    "    \n",
    "    active_site_peptides = {}\n",
    "    for k,v in functionalsites.items():\n",
    "        if str(v) == 'nan':\n",
    "            continue\n",
    "        else: \n",
    "            try: \n",
    "                seqs = seq[k]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            pept = []\n",
    "            for x in v: \n",
    "                pept.append(seqs[x-3:x+3])\n",
    "                active_site_peptides.update({k:pept})\n",
    "    \n",
    "    # 2) Extract coordinates from PDB for the functional site of interest\n",
    "    \n",
    "    active_site_coord = {}\n",
    "    Pep_representative_PDB = convert_df_to_dict(df,colname_pep,\"representative_PDB\")\n",
    "    for kk, v in active_site_peptides.items():\n",
    "        try:\n",
    "            for k in pep_dict[kk]:\n",
    "                representative_pdb = Pep_representative_PDB[k][0]\n",
    "\n",
    "                if str(representative_pdb) ==\"nan\":\n",
    "                    continue\n",
    "                else:\n",
    "                    name = representative_pdb.split(\"_\")[0]+\".pdb\"\n",
    "                    chain = representative_pdb.split(\"_\")[1]\n",
    "                    s  = extract_sequence_from_pdb(name,chain)\n",
    "\n",
    "                    for x in v: \n",
    "                        try:\n",
    "                            match = re.search(x,s)\n",
    "                            match2 =  match.start()+2\n",
    "                            \n",
    "                            xx = extract_coords(name,chain)\n",
    "                            pep_coordinates = xx[match2]\n",
    "            \n",
    "                            append_value(active_site_coord,kk,pep_coordinates)\n",
    "\n",
    "                        except:\n",
    "                            continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "    # 3) Compute minimal distance\n",
    "    \n",
    "    pep_min_dist_to_active_site = {}\n",
    "    for k,v in pep_coord.items():\n",
    "\n",
    "        try:\n",
    "            active = active_site_coord[k]\n",
    "        except:\n",
    "            continue\n",
    "        if str(active) == \"nan\":\n",
    "            continue\n",
    "        else:\n",
    "            for kk,vv in v.items():\n",
    "\n",
    "                temp_active = []\n",
    "                for vvv in vv:\n",
    "\n",
    "                    for a in active:\n",
    "                        dist = np.linalg.norm(vvv-a)\n",
    "                        temp_active.append(dist)\n",
    "                    \n",
    "                pep_min_dist_to_active_site.update({kk:min(temp_active)})\n",
    "                \n",
    "    \n",
    "    return pep_min_dist_to_active_site\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### compute distance to active sites, binding sites etc and add to the dataframe df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dist = compute_distance_to_func_site(activesites,df3,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bind_dist = compute_distance_to_func_site(bindingsites,df3,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_dist = compute_distance_to_func_site(calciumbinding,df3,p)\n",
    "nucleotide_dist = compute_distance_to_func_site(nucleotidebinding,df3,p)\n",
    "metal_dist = compute_distance_to_func_site(metalbinding,df3,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"distance_act_site\"] = df3[pep].map(act_dist)\n",
    "df3[\"distance_bind_site\"] = df3[pep].map(bind_dist)\n",
    "df3[\"distance_ca_binding\"] = df3[pep].map(ca_dist)\n",
    "df3[\"distance_nucleotide_binding\"] = df3[pep].map(nucleotide_dist)\n",
    "df3[\"distance_metal_binding\"] = df3[pep].map(metal_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3[df3[\"representative_PDB\"].notnull()].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UniProt entry P00350 (6-phosphogluconate dehydrogenase, decarboxylating) is an illustrative example with many peptides detected, an available PDB structure, and for which active sites, binding sites and nucleotide binding sites are annotated in UniProt. Distances for each peptide to the closest functional site are computed (see above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindingsites[\"P00350\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activesites[\"P00350\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotidebinding[\"P00350\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute distances manually between selected peptides or peptide/ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_HETATM_ID(infile,chain):\n",
    "    '''''\n",
    "    This function is able to get the HETATM (except water) ID from a PDB file. It returns a dictionary with the format PDB:[NAMES OF LIGANDS].\n",
    "    Input: a PDB file and the chain name. \n",
    "    Example: extract_HETATM_ID(\"PATH/TO/FILE/6xvf.pdb\",\"A\")\n",
    "    '''''\n",
    "\n",
    "    i = open(infile,\"r\")\n",
    "    i = i.readlines()\n",
    "    ligands = []\n",
    "    ligands2 = []\n",
    "    PDBLIG={}\n",
    "    for line in i:\n",
    "        if line.startswith(\"HETATM\"):\n",
    "            if line[17:20] != \"HOH\":\n",
    "                ligand = line[17:20]\n",
    "                ligands.append(ligand)\n",
    "    ligands2 = list(set(ligands))\n",
    "    PDBLIG[infile.strip(\"_HETATM.pdb\")] = ligands2\n",
    "    return PDBLIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(PDB1, chain1, pep1, PDB2, chain2, pep2,mode=\"CA\"):\n",
    "    \n",
    "    '''''\n",
    "    Function to compute the distance between two peptides in either the same or different PDB files.\n",
    "    Example: compute_distance(\"/PATH/TO/FILE/4jhw.pdb\",\"CHAIN\",\"PEPTIDEK\",\"/PATH/TO/FILE/4jhw.pdb\",\"CHAIN\",\"PEPTIDEK\",mode=\"CA\")\n",
    "    currently only works in Calpha mode. Measuring distances between all atoms will be added later. \n",
    "    \n",
    "    '''''\n",
    "        \n",
    "    i1 = open(PDB1,\"r\").readlines()\n",
    "    i2 = open(PDB2,\"r\").readlines()\n",
    "    coords_pep1 = []\n",
    "    coords_pep2 = []\n",
    "    distances = []\n",
    "    i1_seq = extract_sequence_from_pdb(PDB1, chain1)\n",
    "    i2_seq = extract_sequence_from_pdb(PDB2, chain2)\n",
    "    \n",
    "    i1_list = []\n",
    "    i2_list = []\n",
    "    \n",
    "    \n",
    "    match1 = re.search(pep1,i1_seq)\n",
    "    if match1 is None:\n",
    "        raise Exception(\"peptide sequence \"+pep1 + \" was not found in \"+PDB1) \n",
    "        \n",
    "    \n",
    "    match2 = re.search(pep2,i2_seq)\n",
    "    if match2 is None:\n",
    "        raise Exception(\"peptide sequence \"+pep2 + \" was not found in \"+PDB2) \n",
    "    \n",
    "    \n",
    "    if mode==\"CA\":\n",
    "\n",
    "        for line in i1: \n",
    "            if line.startswith(\"ATOM\"):\n",
    "                if line[21:22].strip() == chain1:\n",
    "                    if line[13:16].strip() == \"CA\":\n",
    "                        i1_list.append(line)\n",
    "       \n",
    "        for x in i1_list[match1.start():match1.end()]:\n",
    "\n",
    "            x_coord = float(x[31:38].strip())\n",
    "            y_coord = float(x[39:46].strip())\n",
    "            z_coord = float(x[47:54].strip())\n",
    "            ar = np.array([x_coord,y_coord,z_coord])\n",
    "            coords_pep1.append(ar)\n",
    "\n",
    "\n",
    "        for line in i2: \n",
    "            if line.startswith(\"ATOM\"):\n",
    "                if line[21:22].strip() == chain2:\n",
    "                    if line[13:16].strip() == \"CA\":\n",
    "                        i2_list.append(line)\n",
    "\n",
    "        for x in i2_list[match2.start():match2.end()]:\n",
    "\n",
    "            x_coord = float(x[31:38].strip())\n",
    "            y_coord = float(x[39:46].strip())\n",
    "            z_coord = float(x[47:54].strip())\n",
    "            ar = np.array([x_coord,y_coord,z_coord])\n",
    "            coords_pep2.append(ar)\n",
    "\n",
    "        for c in coords_pep1:\n",
    "            for c2 in coords_pep2:\n",
    "                dist = np.linalg.norm(c-c2)\n",
    "                distances.append(dist)\n",
    "   \n",
    "                \n",
    "    print(\"Minmal distance is: \"+str(min(distances))+\" Å\")\n",
    "    \n",
    "    #return min(distances)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_HETATM(PDB1, chain1, pep1, PDB2, HETATM):\n",
    "    \n",
    "    '''''\n",
    "    Function to compute the distance between a peptide and a ligand/HETATM. \n",
    "    Example: compute_distance(\"/PATH/TO/FILE/4jhw.pdb\",\"CHAIN\",\"PEPTIDEK\",\"/PATH/TO/FILE/4jhw.pdb\",\"LIGAND_ID\")\n",
    "    You can look up the ID of the ligand by calling the function \"extract_HETATM_ID(PDBFILE,CHAIN)\".\n",
    "    '''''\n",
    "        \n",
    "    i1 = open(PDB1,\"r\").readlines()\n",
    "    i2 = open(PDB2,\"r\").readlines()\n",
    "    coords_pep1 = []\n",
    "    coords_pep2 = []\n",
    "    distances = []\n",
    "    i1_seq = extract_sequence_from_pdb(PDB1, chain1)\n",
    "    match1 = re.search(pep1,i1_seq)\n",
    "    i1_list = []\n",
    "    i2_list = []\n",
    "    \n",
    "    if match1 is None:\n",
    "        raise Exception(\"peptide sequence \"+pep1 + \" was not found in \"+PDB1) \n",
    "\n",
    "\n",
    "    for line in i1: \n",
    "        if line.startswith(\"ATOM\"):\n",
    "            if line[21:22].strip() == chain1:\n",
    "                if line[13:16].strip() == \"CA\":\n",
    "                    i1_list.append(line)\n",
    "\n",
    "    for x in i1_list[match1.start():match1.end()]:\n",
    "\n",
    "        x_coord = float(x[31:38].strip())\n",
    "        y_coord = float(x[39:46].strip())\n",
    "        z_coord = float(x[47:54].strip())\n",
    "        ar = np.array([x_coord,y_coord,z_coord])\n",
    "        coords_pep1.append(ar)\n",
    "\n",
    "\n",
    "    for line in i2: \n",
    "        if line.startswith(\"HETATM\"):\n",
    "           \n",
    "                if line[17:20].strip() == HETATM:\n",
    "                        i2_list.append(line)\n",
    "\n",
    "    for x in i2_list:\n",
    "\n",
    "        x_coord = float(x[31:38].strip())\n",
    "        y_coord = float(x[39:46].strip())\n",
    "        z_coord = float(x[47:54].strip())\n",
    "        ar = np.array([x_coord,y_coord,z_coord])\n",
    "        coords_pep2.append(ar)\n",
    "\n",
    "    for c in coords_pep1:\n",
    "        for c2 in coords_pep2:\n",
    "            dist = np.linalg.norm(c-c2)\n",
    "            distances.append(dist)\n",
    "   \n",
    "                \n",
    "    print(\"Minmal distance to ligand is: \" + str(min(distances))+ \" Å\")\n",
    "    \n",
    "    #return min(distances) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples \n",
    "\n",
    "##### Distance between two peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_distance(\"./data/1FKL.pdb\",\"A\",\"GKQEVIR\",\"./data/1FKL.pdb\",\"A\",\"KFDSSRDR\",mode=\"CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get ID of the bound ligands and compute distance between the ligand and a peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_HETATM_ID(\"./data/1FKL.pdb\",\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_distance_HETATM(\"./data/1FKL.pdb\",\"A\",\"GKQEVIR\",\"./data/1FKL.pdb\",\"RAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Plotting structural parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig, ([ax1, ax2,ax3]) = plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "fig.suptitle((\"Secondary structure content on peptide level\"), y=1,fontsize=16)\n",
    "\n",
    "sns.boxplot(y=\"%helix_pep\", x=\"significant\", data=df, palette=[\"#707070\",\"#FF741F\"],ax = ax1,showfliers=False).set_ylabel(\"% helical\")\n",
    "sns.boxplot(y=\"%beta_pep\", x=\"significant\", data=df, palette=[\"#707070\",\"#FF741F\"],ax = ax2,showfliers=False).set_ylabel(\"% beta\")\n",
    "sns.boxplot(y=\"%loop_pep\", x=\"significant\", data=df, palette=[\"#707070\",\"#FF741F\"],ax = ax3,showfliers=False).set_ylabel(\"% loop\")\n",
    "\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
